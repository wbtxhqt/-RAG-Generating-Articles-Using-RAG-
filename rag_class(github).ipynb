{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载数据库\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4498/4498 [00:00<00:00, 7333.04it/s] \n",
      "/home/wuyujie/anaconda3/envs/p310/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载embedding模型\n",
      "正在加载向量数据库\n",
      "----------using 2*GPUs----------\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import tongyi\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import alibabacloud_opensearch, faiss \n",
    "from langchain_community.embeddings import baidu_qianfan_endpoint\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from FlagEmbedding import FlagReranker\n",
    "from langchain_community.document_loaders import DirectoryLoader, text\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class RAGSystem:\n",
    "    def __init__(self, data_directory, \n",
    "                 model_name=\"gpt-4o\", \n",
    "                 embedding_model_name='BAAI/bge-m3', \n",
    "                 cache_folder=\"your_model_save_path\", \n",
    "                 vector_db_path=\"your_vec_model_save_path\"):\n",
    "        # vector_db_path，向量数据库路径\n",
    "        # temperature越高文案生成越宽泛，越低越严格，（0.0，2.0）\n",
    "        self.llm = ChatOpenAI(model_name=model_name, \n",
    "                              api_key=\"your_api\", \n",
    "                              temperature=1.2, \n",
    "                              )\n",
    "        \n",
    "        self.data_directory = data_directory\n",
    "        self.text_splitter = self._initialize_text_splitter()\n",
    "        self.RDATA = self._load_and_split_data(self.data_directory)\n",
    "        self.embedding_model = self._initialize_embedding_model(embedding_model_name, cache_folder)\n",
    "        self.cosine_knowledge_vector_database = self._load_vector_db(vector_db_path)\n",
    "        self.retriever_vectordb = self.cosine_knowledge_vector_database.as_retriever()\n",
    "        self.keyword_retriever = BM25Retriever.from_documents(self.RDATA, k=50, bm25_params={'k1': 1.5})\n",
    "        self.ensemble_retriever = EnsembleRetriever(retrievers=[self.retriever_vectordb, self.keyword_retriever], weights=[0.5, 0.5])\n",
    "        self.reranker = self._initialize_reranker()\n",
    "\n",
    "    def _initialize_text_splitter(self):\n",
    "        MARKDOWN_SEPARATORS = [\n",
    "            \"\\n#{1,6} \", \"```\\n\", \"\\n\\\\*\\\\*\\\\*+\\n\", \"\\n---+\\n\", \"\\n___+\\n\", \"\\n\\n\", \"\\n\", \" \", \"\", \".\", \",\", \n",
    "            \"\\u200B\", \"\\uff0c\", \"\\u3001\", \"\\uff0e\", \"\\u3002\"\n",
    "        ]\n",
    "        return RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True,\n",
    "            separators=MARKDOWN_SEPARATORS,\n",
    "        )\n",
    "\n",
    "    def _load_and_split_data(self, path):\n",
    "        data_loader = DirectoryLoader(path, glob=\"*.txt\", recursive=True, loader_cls=text.TextLoader)\n",
    "        raw_knowledge_base = data_loader.load()\n",
    "        data = []\n",
    "        print(\"正在加载数据库\")\n",
    "        for doc in tqdm(raw_knowledge_base):\n",
    "            data += self.text_splitter.split_documents([doc])\n",
    "        \n",
    "        # Remove duplicates\n",
    "        data_index = {}\n",
    "        RDATA = []\n",
    "        for doc in data:\n",
    "            if doc.page_content not in data_index:\n",
    "                data_index[doc.page_content] = True\n",
    "                RDATA.append(doc)\n",
    "        return RDATA\n",
    "\n",
    "    def _initialize_embedding_model(self, model_name, cache_folder):\n",
    "        print(\"正在加载embedding模型\")\n",
    "        return HuggingFaceEmbeddings(\n",
    "            model_name=model_name,\n",
    "            cache_folder=cache_folder,\n",
    "            multi_process=True,\n",
    "            model_kwargs={\"device\": \"cuda:0\", \"trust_remote_code\": True},\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )\n",
    "\n",
    "    def _load_vector_db(self, vector_db_path):\n",
    "        print(\"正在加载向量数据库\")\n",
    "        cosine_knowledge_vector_database = faiss.FAISS.load_local(vector_db_path, embeddings=self.embedding_model, allow_dangerous_deserialization=True)\n",
    "        return cosine_knowledge_vector_database\n",
    "\n",
    "    def _initialize_reranker(self):\n",
    "        return FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True, cache_dir=\"your_model_save_path\")\n",
    "    \n",
    "    def add_vectorize_data(self, new_data_path, vec_data_path, save_path):\n",
    "        # 将数据库向量化，非必须，每次加入新数据库时使用\n",
    "        # data_path，新数据文件夹路径\n",
    "        # vec_data_path, 旧向量数据库路径\n",
    "        # save_path, 新向量数据库路径\n",
    "        print(\"正在合并数据库\")\n",
    "        knowledge_vector_database = self._load_vector_db(vec_data_path)\n",
    "        RDATA = self._load_and_split_data(new_data_path)\n",
    "        add_ed_index = knowledge_vector_database.add_documents(RDATA)\n",
    "        knowledge_vector_database.save_local(save_path)\n",
    "\n",
    "    def get_relevant_knowledge(self, query, final_extract_num=20):\n",
    "        relevant_doc = self.ensemble_retriever.invoke(query)\n",
    "        temp_docs = [[query, doc.page_content] for doc in relevant_doc]\n",
    "        score = self.reranker.compute_score(temp_docs)\n",
    "        index = np.argsort(score)[-final_extract_num:][::-1]\n",
    "        final_retrieval = [relevant_doc[i].page_content for i in index]\n",
    "        return final_retrieval\n",
    "\n",
    "    def generate_script(self, query):\n",
    "        print(\"正在生成大纲\")\n",
    "        query_retrieval = self.get_relevant_knowledge(query)\n",
    "        context = ''.join([f'文件{i}: {doc}' for i, doc in enumerate(query_retrieval)])\n",
    "        script_prompt_template = PromptTemplate.from_template('''\n",
    "            参考资料:\n",
    "            {context}\n",
    "            你的大纲。\n",
    "            主题:\n",
    "            {query}\n",
    "            答案:\n",
    "            ''')\n",
    "        chain = script_prompt_template | self.llm\n",
    "        script = chain.invoke({'query': query, 'context': context})\n",
    "        return script.content\n",
    "\n",
    "    def extract_keywords(self, query, script):\n",
    "        # 提取关键词\n",
    "        important_extraction_prompt = PromptTemplate.from_template('''\n",
    "            以下是一篇根据主题写的大纲，提取其中的关键词以供后续在资料库中搜索。\n",
    "            主题：\n",
    "            {query}                                                           \n",
    "            大纲：\n",
    "            {script}\n",
    "            ''')\n",
    "        chain = important_extraction_prompt | self.llm\n",
    "        important = chain.invoke({\"query\": query, \"script\": script})\n",
    "        return important.content\n",
    "\n",
    "    def generate_article(self, query):\n",
    "        # 围绕主题生成大纲\n",
    "        script = self.generate_script(query)\n",
    "        # 提取大纲中的关键词\n",
    "        important = self.extract_keywords(query, script)\n",
    "        # 根据关键词二次搜索\n",
    "        important_retrieval = self.get_relevant_knowledge(important)\n",
    "        context = ''.join([f'文件{i}: {doc}' for i, doc in enumerate(important_retrieval)])\n",
    "        print(\"正在生成文案\")\n",
    "        prompt_template = PromptTemplate.from_template('''\n",
    "                                                    \n",
    "        参考资料:\n",
    "        {context} \n",
    "                                                    \n",
    "        你的prompt。\n",
    "                                                                                                \n",
    "        大纲:\n",
    "        {script}\n",
    "\n",
    "        答案:\n",
    "        ''')\n",
    "        chain = prompt_template | self.llm\n",
    "        article = chain.invoke({'script': script, 'context': context})\n",
    "        return article.content\n",
    "\n",
    "# Example usage:\n",
    "# data_directory是文本资料库路径\n",
    "rag_system = RAGSystem(data_directory=\"your_data_path\")\n",
    "query = \"\"\n",
    "answer = rag_system.generate_article(query)\n",
    "# script = rag_system.generate_script(query)\n",
    "# keywords = rag_system.extract_keywords(query, script)\n",
    "# important_retrieval = rag_system.get_relevant_knowledge(keywords, final_extract_num=30）\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
